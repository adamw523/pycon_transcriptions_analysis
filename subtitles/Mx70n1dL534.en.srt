1
00:00:00,060 --> 00:00:03,230
like to do sustern Travis re talking
about you coded character encoding this

2
00:00:03,230 --> 00:00:03,699
morning

3
00:00:03,699 --> 00:00:09,530
help icon

4
00:00:09,530 --> 00:00:13,740
I'm Travis this is Esther we're very
excited to be with you this morning

5
00:00:13,740 --> 00:00:16,880
a drunk last night that we can figure
out how to get the slides up some

6
00:00:16,880 --> 00:00:19,060
feeling really good about Pike on so far

7
00:00:19,060 --> 00:00:22,590
I after I've worked at cars that come
new cars dot com

8
00:00:22,590 --> 00:00:27,090
together for the last couple years papon
shop icon sponsor

9
00:00:27,090 --> 00:00:30,740
users a pyramid Esther still at the
great team at cars dot com

10
00:00:30,740 --> 00:00:33,920
I'm with another Los Angeles Python shop
ship dot com

11
00:00:33,920 --> 00:00:38,770
so I want to introduce you to Cody code
is experiencing pain

12
00:00:38,770 --> 00:00:43,219
experienced the frustration and
confusion so wise Cody experience to me

13
00:00:43,219 --> 00:00:43,840
things

14
00:00:43,840 --> 00:00:47,760
well he's dealing with the heart bleed
blog on his website but on top of that

15
00:00:47,760 --> 00:00:49,480
he's trying to write software

16
00:00:49,480 --> 00:00:54,090
that deals with character encoding and
unique code and if you are anything like

17
00:00:54,090 --> 00:00:58,859
aster myself for Cody it brings about
these emotions

18
00:00:58,859 --> 00:01:02,469
when you're trying to write software
that deals with character encoding and

19
00:01:02,469 --> 00:01:05,790
in may result in that the legendary
double table flip

20
00:01:05,790 --> 00:01:10,290
cell we're hoping this talk will help to
alleviate some about pain for you

21
00:01:10,290 --> 00:01:13,869
speaking a flipping tables

22
00:01:13,869 --> 00:01:17,880
we have a confession to make we chose
the title over talk now just because

23
00:01:17,880 --> 00:01:22,080
it is art is silly and fun but because
we were evil as the pike our program

24
00:01:22,080 --> 00:01:25,689
committee found out when our talk title
crashed PIRC thought that they use when

25
00:01:25,689 --> 00:01:25,970
they

26
00:01:25,970 --> 00:01:29,210
review proposals we really drove home
the point that

27
00:01:29,210 --> 00:01:33,390
this is a topic that's very relevant to
anyone who's ever had to deal with texts

28
00:01:33,390 --> 00:01:35,009
character encoding in your code

29
00:01:35,009 --> 00:01:39,020
which is all of us at some point in our
careers before continuing

30
00:01:39,020 --> 00:01:42,640
I have to mention that we're not going
to talk about Python 3 in our talk

31
00:01:42,640 --> 00:01:45,790
we do want to cover the fundamentals
love tax

32
00:01:45,790 --> 00:01:49,200
characters character encoding unique
code and streams

33
00:01:49,200 --> 00:01:53,329
so that you can understand at a
fundamental level how those things work

34
00:01:53,329 --> 00:01:56,240
and that will make it easier for you to
understand the differences between the

35
00:01:56,240 --> 00:01:57,329
way Python 3

36
00:01:57,329 --> 00:02:00,880
and Python to handle text and character
encoding

37
00:02:00,880 --> 00:02:05,759
but we just don't have time to talk
about this today we're gonna start up

38
00:02:05,759 --> 00:02:07,009
with the fundamentals

39
00:02:07,009 --> 00:02:11,870
an amana mention I met Batchelder give a
fantastic talk by Con 2012

40
00:02:11,870 --> 00:02:15,489
on the fundamental view record in
character encoding help tester and I

41
00:02:15,489 --> 00:02:16,770
understand it a lot

42
00:02:16,770 --> 00:02:20,420
so I recommend go check back talk out
the video as soon as you can if you

43
00:02:20,420 --> 00:02:21,220
haven't seen it

44
00:02:21,220 --> 00:02:25,590
we're gonna try and build on that and I
take your little further

45
00:02:25,590 --> 00:02:28,989
so fundamentals humans use tax

46
00:02:28,989 --> 00:02:32,239
to communicate right we use written
language we use characters

47
00:02:32,239 --> 00:02:35,910
the computer speak bites computers on a
fundamental level

48
00:02:35,910 --> 00:02:40,030
just deal with binary so how do we deal
with that will be as programmers

49
00:02:40,030 --> 00:02:43,500
need to translate are written taxed into
binary

50
00:02:43,500 --> 00:02:46,930
we use something called character
encoding you guys know this right

51
00:02:46,930 --> 00:02:50,950
we take a character like the lower case
Latin a and we just map it

52
00:02:50,950 --> 00:02:54,450
to some binary representation we assign
it some bets

53
00:02:54,450 --> 00:02:57,709
this is the ASCII encoding for the lower
case a

54
00:02:57,709 --> 00:03:00,840
cell there's a bunch a different
character encodings out there

55
00:03:00,840 --> 00:03:05,209
they're all unique they do things
differently they do try to agree and

56
00:03:05,209 --> 00:03:06,700
have some compatibility

57
00:03:06,700 --> 00:03:10,019
for like your basic a disease that
that's represented in ASCII

58
00:03:10,019 --> 00:03:13,019
but because their unique encoding they
differ

59
00:03:13,019 --> 00:03:17,900
a character like the Euro symbol is
represented with different binary

60
00:03:17,900 --> 00:03:22,209
representations in these various
encodings and the result that bat

61
00:03:22,209 --> 00:03:26,459
is that the same binary sequence may
represent

62
00:03:26,459 --> 00:03:29,970
two different characters depending on
what encoding you are using

63
00:03:29,970 --> 00:03:36,230
and this is because of a lot of pain
what think about all the characters that

64
00:03:36,230 --> 00:03:38,590
we like to use in our written
communication

65
00:03:38,590 --> 00:03:43,290
but don't lie under sorry don't but
don't fall under the standard it is

66
00:03:43,290 --> 00:03:44,129
easier

67
00:03:44,129 --> 00:03:47,260
9 range to ASCII presents us we like to
use

68
00:03:47,260 --> 00:03:50,580
mathematical symbols punctuation marks
and even

69
00:03:50,580 --> 00:03:54,610
unico snowmen and of course there are
other languages in English that have

70
00:03:54,610 --> 00:03:55,390
their own scripts

71
00:03:55,390 --> 00:03:58,569
some other have dozens or even hundreds
of characters that also need to be

72
00:03:58,569 --> 00:03:59,370
encoded

73
00:03:59,370 --> 00:04:04,319
so unique code was away to standardize a
way that we can encode

74
00:04:04,319 --> 00:04:09,099
any character that anyone might ever
want to encode the unico does this

75
00:04:09,099 --> 00:04:12,290
is by providing a universally recognized
mapping

76
00:04:12,290 --> 00:04:15,580
between a character any Unicode code
point

77
00:04:15,580 --> 00:04:19,359
this is a universally recognized
identifiers for character

78
00:04:19,359 --> 00:04:23,720
its denoted by a capital you in a plus
sign followed by a unique exodus more

79
00:04:23,720 --> 00:04:24,300
value

80
00:04:24,300 --> 00:04:27,880
assigned uniquely to that character what
you should know

81
00:04:27,880 --> 00:04:32,370
is that unico does not provide aid
binary mapping for a character

82
00:04:32,370 --> 00:04:36,720
code points are purely an abstraction
layer its limited a character itself

83
00:04:36,720 --> 00:04:39,820
its wholly separate from any binary
representation

84
00:04:39,820 --> 00:04:43,280
it's purely a description for a
character

85
00:04:43,280 --> 00:04:46,710
of course ultimately computers you need
bites to deal with taxi

86
00:04:46,710 --> 00:04:50,169
transmitted and store it so what we need
is a way to map

87
00:04:50,169 --> 00:04:53,169
between a unique code code point for
every character

88
00:04:53,169 --> 00:04:58,030
to that binary representation so what we
need is a unique 02 where

89
00:04:58,030 --> 00:05:01,650
encoding unico transformation format are
you tee eff

90
00:05:01,650 --> 00:05:05,490
which there are several but the one that
you should use wherever you can

91
00:05:05,490 --> 00:05:10,120
is utf8 for many reasons it's become the
defacto standard used across

92
00:05:10,120 --> 00:05:14,090
the Internet is by email clients
internet browsers

93
00:05:14,090 --> 00:05:19,570
and operating systems so Esther just
explain unit code in utf8 right

94
00:05:19,570 --> 00:05:23,570
these are highly related terms but I
just wanna drive home the point

95
00:05:23,570 --> 00:05:27,860
they are unique ideas and you should
just blindly use those terms

96
00:05:27,860 --> 00:05:29,490
interchangeably unit code

97
00:05:29,490 --> 00:05:33,800
is code points unique identifiers that
are universally known and accepted for

98
00:05:33,800 --> 00:05:34,729
characters

99
00:05:34,729 --> 00:05:38,630
you tee eff a UT F-sixteen these are
binary encodings

100
00:05:38,630 --> 00:05:42,470
for those code points to just keep those
separate in your mind

101
00:05:42,470 --> 00:05:46,720
so sorry I'm I

102
00:05:46,720 --> 00:05:49,990
let's talk layers and abstraction let's
put this all in a little bit a context

103
00:05:49,990 --> 00:05:50,780
right

104
00:05:50,780 --> 00:05:54,770
on a high level I'm gonna use the
computer my

105
00:05:54,770 --> 00:05:58,360
could have stopped working I on
high-level you deal with

106
00:05:58,360 --> 00:06:01,569
the display layer right you show
characters on the screen

107
00:06:01,569 --> 00:06:05,130
you print them I best I life characters
called the glyph

108
00:06:05,130 --> 00:06:08,919
you render it using font rendering
exciter a below that

109
00:06:08,919 --> 00:06:13,340
you have the tax Slayer abstraction this
deals with the elements are written in

110
00:06:13,340 --> 00:06:14,310
languages

111
00:06:14,310 --> 00:06:17,610
this is what we as humans deal with
right this is what you need coating code

112
00:06:17,610 --> 00:06:21,169
point tries to address it gives unique
ID's to those characters

113
00:06:21,169 --> 00:06:24,500
but ultimately computers big bites we
need to start transmit them

114
00:06:24,500 --> 00:06:28,530
so we need something like utf8 to
represented in binary

115
00:06:28,530 --> 00:06:32,210
those are the layers are gonna have to
deal with how does Python deal with this

116
00:06:32,210 --> 00:06:35,740
law specifically to seven cuz three is
different right a should go learn about

117
00:06:35,740 --> 00:06:37,100
that if you can use three

118
00:06:37,100 --> 00:06:40,690
but Python 27 gives you the string type
the sister type

119
00:06:40,690 --> 00:06:43,770
this is a byte string it's a sequence a
bite

120
00:06:43,770 --> 00:06:47,530
that represent tax and what that implies
is there's a specific

121
00:06:47,530 --> 00:06:51,490
character encoding there there's no such
thing as like plain text bite

122
00:06:51,490 --> 00:06:55,060
there's always a character encoding you
need to know it Python also gives you

123
00:06:55,060 --> 00:06:56,349
the unico type

124
00:06:56,349 --> 00:07:00,860
this deals with cold points this deals
with that tax abstraction layer

125
00:07:00,860 --> 00:07:04,330
so even though python has an internal
representation when you're dealing with

126
00:07:04,330 --> 00:07:07,729
the Unicode object you is the programmer
don't need to worry

127
00:07:07,729 --> 00:07:12,819
about been coding this is characters
this is unique code code points

128
00:07:12,819 --> 00:07:15,590
you really need to translate between
your bike you bite strengthen your

129
00:07:15,590 --> 00:07:17,479
unique coating by spur so how do you do
that

130
00:07:17,479 --> 00:07:20,630
of you have some bites need tournament
the unit code

131
00:07:20,630 --> 00:07:24,789
that's the decode operation your
decoding your encoded bites into unit

132
00:07:24,789 --> 00:07:25,340
code

133
00:07:25,340 --> 00:07:28,680
going the other direction you've got a
unique code object you want to encoded

134
00:07:28,680 --> 00:07:31,449
into bites you can store transmit well

135
00:07:31,449 --> 00:07:35,759
it's the encode function right be in
cooperation up for beginners sometimes

136
00:07:35,759 --> 00:07:39,090
keeping the straight and the directions
as a little tricky I came up with this

137
00:07:39,090 --> 00:07:40,039
name on it device

138
00:07:40,039 --> 00:07:44,479
I using my had I just misspelled the
function name za five bites I B code

139
00:07:44,479 --> 00:07:46,550
them at five unico to you in code them

140
00:07:46,550 --> 00:07:50,590
I don't that's helpful for you but i
thought id throw it out there

141
00:07:50,590 --> 00:07:54,110
for the fundamental thing that you need
to know about a byte string is that it

142
00:07:54,110 --> 00:07:56,560
contains no information it have itself

143
00:07:56,560 --> 00:08:00,699
about how each sequence of bytes what
should be decoded back into

144
00:08:00,699 --> 00:08:05,419
the character you have to be told fire
some sort of external declaration

145
00:08:05,419 --> 00:08:09,340
what encoding was used to store that
text as a byte string

146
00:08:09,340 --> 00:08:12,720
so you might find this in a document
header an ATP header

147
00:08:12,720 --> 00:08:16,470
or other file meta-data or even a code
commenter email from a coworker telling

148
00:08:16,470 --> 00:08:16,789
you

149
00:08:16,789 --> 00:08:20,720
when encoding was used the point is if
you don't know what encoding was used on

150
00:08:20,720 --> 00:08:21,830
a given byte string

151
00:08:21,830 --> 00:08:25,690
you can't figure it out just by looking
at the string you have to be told

152
00:08:25,690 --> 00:08:29,220
when encoding was used or else you can
be sure that your decoding properly back

153
00:08:29,220 --> 00:08:31,879
into the original text

154
00:08:31,879 --> 00:08:35,419
so knowing these fundamentals what can
we as Python developers due to write

155
00:08:35,419 --> 00:08:36,760
applications to handle

156
00:08:36,760 --> 00:08:40,640
our text properly but what they're a
simple application that we're gonna

157
00:08:40,640 --> 00:08:42,640
build right here

158
00:08:42,640 --> 00:08:46,550
let's say that we have this year see
files are datasource and it contains a

159
00:08:46,550 --> 00:08:47,990
bunch of car reviews cover

160
00:08:47,990 --> 00:08:51,920
car website we're gonna write a simple
python application to do some processing

161
00:08:51,920 --> 00:08:53,240
overtaxed

162
00:08:53,240 --> 00:08:56,320
and store in a texan oppose Chris
database so that ultimately we can

163
00:08:56,320 --> 00:08:57,760
render in a browser

164
00:08:57,760 --> 00:09:01,149
on a website like new cars are calm

165
00:09:01,149 --> 00:09:04,810
let's take a look at our source file the
city file you can see is created using

166
00:09:04,810 --> 00:09:06,370
Microsoft Excel

167
00:09:06,370 --> 00:09:09,200
and the person who sent us this file
says he used a really old version of

168
00:09:09,200 --> 00:09:09,990
Windows

169
00:09:09,990 --> 00:09:16,560
and so we're gonna say that this was
windows for 52 encoded RCP 12:52 encoded

170
00:09:16,560 --> 00:09:19,959
our application is very simple we're
just gonna look for instance is that the

171
00:09:19,959 --> 00:09:22,240
word Montreal without any accents

172
00:09:22,240 --> 00:09:25,890
and we're gonna replace it with the word
Montreal it's properly spelled with the

173
00:09:25,890 --> 00:09:28,089
accent over the E

174
00:09:28,089 --> 00:09:31,279
when we store our text data in our
database

175
00:09:31,279 --> 00:09:34,500
we want to use put posters and we're
gonna use utf8

176
00:09:34,500 --> 00:09:38,670
as the encoding that we want to
converter text into by strings attached

177
00:09:38,670 --> 00:09:41,839
because it's a best practice the reason
for this being that

178
00:09:41,839 --> 00:09:45,440
we know that we can handle any character
that comes across from Mercer stated

179
00:09:45,440 --> 00:09:46,750
your application

180
00:09:46,750 --> 00:09:50,550
if we use a targeting coating that is
unico to wear

181
00:09:50,550 --> 00:09:54,420
taking a closer look at an example
review you can see we have

182
00:09:54,420 --> 00:09:57,690
the target word that we're going to
replace with their application I also

183
00:09:57,690 --> 00:10:00,010
want to point out a couple characters
here though

184
00:10:00,010 --> 00:10:04,160
these don't lie inside that a tizzy 029
ASCII range

185
00:10:04,160 --> 00:10:07,510
and so if we were ever to use an
encoding other than are searching

186
00:10:07,510 --> 00:10:09,329
coating of CP 12:52

187
00:10:09,329 --> 00:10:13,350
then we might end up with 8 the risk I
have coming up with a different bites

188
00:10:13,350 --> 00:10:15,200
your representation for these characters

189
00:10:15,200 --> 00:10:19,620
I'm just doing a little foreshadowing
here so let's write some code

190
00:10:19,620 --> 00:10:22,920
skin walking through this line by line
this is our application

191
00:10:22,920 --> 00:10:27,260
we're gonna start off by the Clarion the
in codeine our source code

192
00:10:27,260 --> 00:10:30,720
on the guy should be doing this there's
a number of reasons why but basically

193
00:10:30,720 --> 00:10:31,529
you're telling

194
00:10:31,529 --> 00:10:35,089
potential your text editor but more
importantly the Python interpreter

195
00:10:35,089 --> 00:10:38,790
the bites that are to follow should be
interpreted as being

196
00:10:38,790 --> 00:10:42,860
such encoded and so we're using utf8 for
our encoding

197
00:10:42,860 --> 00:10:46,620
gonna open the file we're gonna iterate
over it line by line

198
00:10:46,620 --> 00:10:49,690
and we're gonna do some very simple CSB
processing

199
00:10:49,690 --> 00:10:53,220
we're just gonna split on the comma and
then we're going to do

200
00:10:53,220 --> 00:10:56,540
some simple text processing we're gonna
call dot replace

201
00:10:56,540 --> 00:11:00,890
on our review taxed we're gonna search
for the Montreal spot without the accent

202
00:11:00,890 --> 00:11:04,430
and we're gonna replace it with the
properly accented version Montreal

203
00:11:04,430 --> 00:11:07,899
and ultimately we're gonna store that in
a database using this simple database

204
00:11:07,899 --> 00:11:10,370
API that we have at our disposal

205
00:11:10,370 --> 00:11:14,560
let's run this code and see what happens

206
00:11:14,560 --> 00:11:18,390
so OK the code ran our date is in the
database

207
00:11:18,390 --> 00:11:21,709
but this is what we're seeing we're
looking at our utf8 encoded Postgres

208
00:11:21,709 --> 00:11:23,000
database and were seen

209
00:11:23,000 --> 00:11:27,010
this not what we're hoping for right
you've got the question mark law singers

210
00:11:27,010 --> 00:11:27,660
in there

211
00:11:27,660 --> 00:11:31,589
something didn't go all right Montreal
did get properly replace so we're happy

212
00:11:31,589 --> 00:11:33,360
about that but we gotta figure out

213
00:11:33,360 --> 00:11:37,529
what's the deal with the Los Angeles so
let's take back into our code and try to

214
00:11:37,529 --> 00:11:38,779
figure it out

215
00:11:38,779 --> 00:11:41,790
we're dealing with tax treaty with
character encoding we're dealing with

216
00:11:41,790 --> 00:11:42,790
byte strings

217
00:11:42,790 --> 00:11:46,500
so I piloted all the byte strings here
and when we have a byte string we know

218
00:11:46,500 --> 00:11:47,440
there's an encoding

219
00:11:47,440 --> 00:11:50,579
what encoding do these bites trains use
well

220
00:11:50,579 --> 00:11:54,240
let's figure it out got are straining
literals

221
00:11:54,240 --> 00:11:57,450
we use the quotes we create a string
type in Python

222
00:11:57,450 --> 00:12:00,870
the string literals are utf8 encoded

223
00:12:00,870 --> 00:12:03,970
why's that while we declare our source
code to be

224
00:12:03,970 --> 00:12:07,350
utf8 encoded and so therefore we also
wrote

225
00:12:07,350 --> 00:12:10,720
bites into that file that were you tee
eff 8

226
00:12:10,720 --> 00:12:15,670
byte strings and Python interprets our
string literals as low as utf8 byte

227
00:12:15,670 --> 00:12:17,339
strings

228
00:12:17,339 --> 00:12:20,589
now we're redeem CP 12:52 data

229
00:12:20,589 --> 00:12:24,160
out of this CSV file so the data that
we're really now

230
00:12:24,160 --> 00:12:27,329
the variables that were signing those
bites trains

231
00:12:27,329 --> 00:12:31,839
RCP 12:52 encoded bite strings that
leaves us with one byte string we

232
00:12:31,839 --> 00:12:34,079
haven't talked about converted review

233
00:12:34,079 --> 00:12:37,370
what character encoding is converted
review well

234
00:12:37,370 --> 00:12:41,600
we're creating converted review and
we're creating it with this operation

235
00:12:41,600 --> 00:12:44,600
we're taking a CP 12:52 byte string

236
00:12:44,600 --> 00:12:48,510
were telling Python dot replace and
we're handing dot replace

237
00:12:48,510 --> 00:12:51,769
utf8 encoded bite strings

238
00:12:51,769 --> 00:12:55,610
Python will happily do that for us
because Python doesn't know about these

239
00:12:55,610 --> 00:12:58,829
encodings pythons just looking at bytes
in this case

240
00:12:58,829 --> 00:13:04,540
so Python created a nice mixed encoding
mass for us really we created it by just

241
00:13:04,540 --> 00:13:06,889
telling Python to do what I time does

242
00:13:06,889 --> 00:13:10,290
and then restored that in our database
so visually

243
00:13:10,290 --> 00:13:13,630
here's what happened right CP 12:52
source data

244
00:13:13,630 --> 00:13:17,790
coming out of our file we tell pipe on
top replace

245
00:13:17,790 --> 00:13:21,450
here is utf8 byte string Python happily

246
00:13:21,450 --> 00:13:25,380
operates on those bites for us and gives
us a byte string that contains some

247
00:13:25,380 --> 00:13:27,459
sleepy 12:52 bites

248
00:13:27,459 --> 00:13:31,709
some utf8 bytes now when we load bat in
our database

249
00:13:31,709 --> 00:13:34,829
client the database client

250
00:13:34,829 --> 00:13:39,300
is looking for utf8 bite has it the utf8
database from the disconnect to it using

251
00:13:39,300 --> 00:13:40,310
utf8

252
00:13:40,310 --> 00:13:44,810
when utf8 database sees BCP 12:52 curly
quotes

253
00:13:44,810 --> 00:13:48,540
and Euro symbol it just throws it hands
up in size those are bite I don't

254
00:13:48,540 --> 00:13:50,970
recognize I can interpret them as utf8

255
00:13:50,970 --> 00:13:54,480
thus the question mark lawson's

256
00:13:54,480 --> 00:13:58,810
to a travis has just illustrated is best
practice one that we recommend

257
00:13:58,810 --> 00:14:02,899
know you're in coatings there's no such
thing as a plain text string

258
00:14:02,899 --> 00:14:07,230
on a computer the only way to store text
on a computer issue encoded into bytes

259
00:14:07,230 --> 00:14:10,480
and you have to know what encoding
you're using the Turner Tech Center

260
00:14:10,480 --> 00:14:12,010
bites

261
00:14:12,010 --> 00:14:16,180
fourth fix our application we know we
want to avoid mixing up in coatings the

262
00:14:16,180 --> 00:14:17,170
way we just did

263
00:14:17,170 --> 00:14:20,500
we should probably be dealing with
Unicode characters so that we're doing

264
00:14:20,500 --> 00:14:21,680
purely on the level

265
00:14:21,680 --> 00:14:26,260
love the text so let's take those row
text objects that we pull from our file

266
00:14:26,260 --> 00:14:30,000
their bites rings what's called decode
on them to turn them into Unicode

267
00:14:30,000 --> 00:14:31,029
objects

268
00:14:31,029 --> 00:14:34,560
then we could split them into to get our
other dating review

269
00:14:34,560 --> 00:14:38,860
text as you code objects as well and
we're also going to replace

270
00:14:38,860 --> 00:14:42,220
the byte string literals in our
application with unico literals

271
00:14:42,220 --> 00:14:45,870
so now we're dealing with you the code
at every level in our application

272
00:14:45,870 --> 00:14:50,389
we should be good to go Ono acceptance
or not

273
00:14:50,389 --> 00:14:54,060
so you've probably seen this error
message many times have you

274
00:14:54,060 --> 00:14:57,980
what is the word ask you doing in that
area message we never declared anything

275
00:14:57,980 --> 00:15:00,610
to be ask your application

276
00:15:00,610 --> 00:15:03,740
let's take a look at the road a cause
the exception inner

277
00:15:03,740 --> 00:15:07,699
intercut so we can't decode on this road
text byte string

278
00:15:07,699 --> 00:15:10,889
but we forgot something we forgot to
tell Python

279
00:15:10,889 --> 00:15:15,410
when according to use when decoding that
bites ring into Unicode object

280
00:15:15,410 --> 00:15:18,860
soap I thought to have some problematic
default behavior

281
00:15:18,860 --> 00:15:22,370
it tries to be helpful and it seems that
you want to use your system's default

282
00:15:22,370 --> 00:15:23,380
encoding

283
00:15:23,380 --> 00:15:26,420
which in most cases is going to be
asking and so

284
00:15:26,420 --> 00:15:29,720
when it encounters have curly quotes
ASCII is going to blow up in

285
00:15:29,720 --> 00:15:33,079
your application is going to fail we've
actually done

286
00:15:33,079 --> 00:15:36,769
is a lesson best practice known as you
could whack a mole

287
00:15:36,769 --> 00:15:39,820
which I'm sure many viewers play we've
played it plenty of times

288
00:15:39,820 --> 00:15:44,079
and it's exacerbated by Python two's
problematic default behavior

289
00:15:44,079 --> 00:15:47,839
the fix is pretty simple you just have
to explicitly d

290
00:15:47,839 --> 00:15:52,410
a declared the encoding that you want to
use in our case this a CP 12:52

291
00:15:52,410 --> 00:15:55,870
are searching coating and so now that
we've declared the encoding

292
00:15:55,870 --> 00:15:59,899
Python can correctly turned that unico
to that biting uptick

293
00:15:59,899 --> 00:16:03,740
into Unicode object also want to point
out that

294
00:16:03,740 --> 00:16:08,000
in the final I never application we
answered our data we now have three

295
00:16:08,000 --> 00:16:12,380
Unicode objects that we wanna stay that
we're sending over to our database

296
00:16:12,380 --> 00:16:15,870
depending on the database that you use
in the features it has are the API that

297
00:16:15,870 --> 00:16:16,160
you

298
00:16:16,160 --> 00:16:19,820
you have at your disposal this may or
may not be a problem

299
00:16:19,820 --> 00:16:23,810
in our case we want to explicitly
encoders you could object

300
00:16:23,810 --> 00:16:27,329
into byte strings and of course we're
going to declare the encoding

301
00:16:27,329 --> 00:16:30,870
that we want to use which is utf8

302
00:16:30,870 --> 00:16:34,170
so whatsoever any application one more
time

303
00:16:34,170 --> 00:16:39,160
and finally we get what we're looking
for everything looks good

304
00:16:39,160 --> 00:16:43,040
so this is best practice number to Astor
just walk you through it

305
00:16:43,040 --> 00:16:47,930
called the unit code sandwich and it's
not quite as delicious as it sounds but

306
00:16:47,930 --> 00:16:49,730
it does make your life nice

307
00:16:49,730 --> 00:16:53,380
so what's take a look at that right you
could sandwiches just this

308
00:16:53,380 --> 00:16:57,720
unit decode from bites early in your
application as soon as you're reading

309
00:16:57,720 --> 00:16:59,079
bites out of eyler

310
00:16:59,079 --> 00:17:02,470
are getting them across the wire decode
them any Unicode then in your

311
00:17:02,470 --> 00:17:03,709
application layer

312
00:17:03,709 --> 00:17:06,980
you can deal with Unicode you can deal
with characters and not have to worry

313
00:17:06,980 --> 00:17:08,559
about character encoding

314
00:17:08,559 --> 00:17:12,150
and then you're gonna in code back into
bite slave in your application before

315
00:17:12,150 --> 00:17:14,439
persisting are transmitting that data

316
00:17:14,439 --> 00:17:17,709
so again what about look like in our
application well esther

317
00:17:17,709 --> 00:17:22,400
decoded from CP 12:52 as she was reading
bites out in the file

318
00:17:22,400 --> 00:17:26,270
and then she encoded into our target
utf8 encoding

319
00:17:26,270 --> 00:17:29,470
immediately before persisting those
bites in the database

320
00:17:29,470 --> 00:17:33,410
and what that allowed is everywhere in
the middle we had delicious blue Unicode

321
00:17:33,410 --> 00:17:34,640
ice cream filling

322
00:17:34,640 --> 00:17:37,770
I'm we didn't have to worry about
character encodings our application

323
00:17:37,770 --> 00:17:41,490
this really does make your life nice if
your application will allow you to use

324
00:17:41,490 --> 00:17:43,730
this pattern

325
00:17:43,730 --> 00:17:47,309
but their best practice at we want to
recommend is for you to write good tests

326
00:17:47,309 --> 00:17:48,990
against your code to make sure that

327
00:17:48,990 --> 00:17:52,650
it is handling text properly you want to
test the ranges

328
00:17:52,650 --> 00:17:55,650
in boundaries are the encoding that
you're using if you're

329
00:17:55,650 --> 00:17:59,919
application is supposed to handle unico
text then be sure that you're using test

330
00:17:59,919 --> 00:18:02,169
strings that contain more than just the

331
00:18:02,169 --> 00:18:06,160
it is easier tonight ask your age there
are fair to text generators online

332
00:18:06,160 --> 00:18:09,539
you can use to generate some crazy unico
characters that you can put

333
00:18:09,539 --> 00:18:15,820
in your tests you also want to test your
interfaces against both Python unico

334
00:18:15,820 --> 00:18:16,370
girls

335
00:18:16,370 --> 00:18:20,309
and byte string literals you may be
using libraries in your application that

336
00:18:20,309 --> 00:18:24,250
do their own unique 02 string
conversions and they may or may not do

337
00:18:24,250 --> 00:18:24,950
it correctly

338
00:18:24,950 --> 00:18:28,610
you can't be sure unless you write tests
so if you have something that expecting

339
00:18:28,610 --> 00:18:29,169
a code

340
00:18:29,169 --> 00:18:32,850
they rode a bike string and see what it
does and if it expects bites throated a

341
00:18:32,850 --> 00:18:33,880
Unicode string is

342
00:18:33,880 --> 00:18:37,700
and see what happens you wanna make sure
that your texts isn't causing problems

343
00:18:37,700 --> 00:18:40,710
as it makes its way through your
application

344
00:18:40,710 --> 00:18:44,580
you also want to test for the handling
of incorrectly coded text if you have

345
00:18:44,580 --> 00:18:46,049
code that expect ASCII

346
00:18:46,049 --> 00:18:49,970
try throwing it some utf8 encoded text
and see and see what happens

347
00:18:49,970 --> 00:18:53,620
maybe you want to raising a right away
so that you know that you have a problem

348
00:18:53,620 --> 00:18:55,570
in your source data that's changed

349
00:18:55,570 --> 00:18:59,500
in Cali authorities complain whatever or
maybe what your application a chug along

350
00:18:59,500 --> 00:19:00,690
without breaking

351
00:19:00,690 --> 00:19:04,860
whatever you do make sure that you're
writing a proper tests for this

352
00:19:04,860 --> 00:19:08,600
so just to recap those best practices
for you always know you're in coatings

353
00:19:08,600 --> 00:19:11,820
cuz there's no such thing as plain tax
right if you have bites

354
00:19:11,820 --> 00:19:15,190
their encoded you need to know when
encoding was used

355
00:19:15,190 --> 00:19:18,669
then wherever you can use the unique
codes and much so that you can deal with

356
00:19:18,669 --> 00:19:21,900
tax with you know Cody your application
layer and you don't have to worry about

357
00:19:21,900 --> 00:19:22,970
encodings

358
00:19:22,970 --> 00:19:27,309
and then finally test your code I hope
this is the best practice you all see

359
00:19:27,309 --> 00:19:28,340
the value n

360
00:19:28,340 --> 00:19:32,549
in Python in general but when you're
talking about texting character encoding

361
00:19:32,549 --> 00:19:36,549
these blogs are sneaky right because
your application is we're keen

362
00:19:36,549 --> 00:19:39,870
and then all the sudden you encounter a
character that comes across Denmark AP

363
00:19:39,870 --> 00:19:41,419
Iran a file

364
00:19:41,419 --> 00:19:45,440
and your application blows up are so
test your text related code

365
00:19:45,440 --> 00:19:48,919
so we know our best practices were using
them

366
00:19:48,919 --> 00:19:52,710
our world is great we're doing the right
thing but ultimately

367
00:19:52,710 --> 00:19:57,500
your system is gonna and Iraq with
outside systems outside external beta

368
00:19:57,500 --> 00:20:01,309
and someone else's system is gonna cause
you pain

369
00:20:01,309 --> 00:20:06,260
so what does that look like what can you
do about it couple quick examples

370
00:20:06,260 --> 00:20:09,940
what happens when you get a file bat is
using

371
00:20:09,940 --> 00:20:13,950
on incorrect encoding or decoding that's
different than what was declared so

372
00:20:13,950 --> 00:20:14,909
example at

373
00:20:14,909 --> 00:20:19,970
we have our application its processing
RCP 12:52 day to day after day month

374
00:20:19,970 --> 00:20:21,630
after month year after year

375
00:20:21,630 --> 00:20:25,700
were happy were enjoying life and then
one day

376
00:20:25,700 --> 00:20:31,289
utf8 shows up and we all know about it
right this was still declared CP 12:52

377
00:20:31,289 --> 00:20:35,020
by at the water cooler conversation with
the coworker two years ago when he told

378
00:20:35,020 --> 00:20:37,490
us he was gonna email SEP 12 52

379
00:20:37,490 --> 00:20:41,610
but one day we get utf8 and we're on our
program

380
00:20:41,610 --> 00:20:44,820
and new killer table flap it blows up

381
00:20:44,820 --> 00:20:48,419
and we're not happy I so how do you deal
with that as well

382
00:20:48,419 --> 00:20:51,720
this is pretty simple one right there's
human interaction

383
00:20:51,720 --> 00:20:54,870
you can go talk to people you can use
your words you can ask am

384
00:20:54,870 --> 00:20:59,820
I what happened what happened to CP
12:52 white agate utf8 did you get a new

385
00:20:59,820 --> 00:21:01,470
program what's going on

386
00:21:01,470 --> 00:21:05,770
on but maybe he left the company or
maybe you're not on speaking terms or

387
00:21:05,770 --> 00:21:09,280
maybe he's up in management more talked
about character encoding anymore

388
00:21:09,280 --> 00:21:12,940
and in that case you're gonna have to
guess and you can just blindly yes you

389
00:21:12,940 --> 00:21:13,700
can say

390
00:21:13,700 --> 00:21:16,750
ASCII utf8 let's try and find out

391
00:21:16,750 --> 00:21:20,400
but that's not a great way to write
quality software so

392
00:21:20,400 --> 00:21:23,890
you can get intelligently by using a
library like chart at no charge that is

393
00:21:23,890 --> 00:21:25,330
just gonna look at your bites

394
00:21:25,330 --> 00:21:28,520
and give you statistical probability on

395
00:21:28,520 --> 00:21:33,490
those bites mean back it was encoded in
a certain encoding so you know this is

396
00:21:33,490 --> 00:21:35,460
ninety percent chance this is utf8

397
00:21:35,460 --> 00:21:38,630
but ultimately that is a gas based on
probability

398
00:21:38,630 --> 00:21:42,260
maybe someone invents a new character
encoding in-charge

399
00:21:42,260 --> 00:21:45,030
that doesn't know about it yet or
something like that just understand it's

400
00:21:45,030 --> 00:21:45,520
a gas

401
00:21:45,520 --> 00:21:49,630
and then again if you wrote your tasks
you already know how your application is

402
00:21:49,630 --> 00:21:51,480
going to fail in this case

403
00:21:51,480 --> 00:21:54,409
and presumably you wrote it in a way
where you are going to have to flip

404
00:21:54,409 --> 00:21:58,700
tables when you encounter utf8 data

405
00:21:58,700 --> 00:22:02,590
another problem that you might encounter
is what if you receive data from an

406
00:22:02,590 --> 00:22:05,200
application developer who didn't watch
our talk

407
00:22:05,200 --> 00:22:08,559
they played a little too much you could
whack a mole so they give you the

408
00:22:08,559 --> 00:22:09,640
strings in your

409
00:22:09,640 --> 00:22:14,270
in in your source data they're all mixed
up they contain garbage characters miss

410
00:22:14,270 --> 00:22:17,710
encoded miss decoded characters mixing
coatings

411
00:22:17,710 --> 00:22:21,710
or just escape characters there's a word
for this

412
00:22:21,710 --> 00:22:25,929
it's called mochi parquet and it's a
real pain affects because first of all

413
00:22:25,929 --> 00:22:26,840
you don't know

414
00:22:26,840 --> 00:22:30,590
what that developer did to give you this
mix-up string and how they missing

415
00:22:30,590 --> 00:22:31,270
coated in

416
00:22:31,270 --> 00:22:34,890
mixed up those in coatings in it in
their tax much less

417
00:22:34,890 --> 00:22:39,059
how are you supposed to know what the
original characters were supposed to be

418
00:22:39,059 --> 00:22:42,419
to use one example that we've
encountered this year is supposed to be

419
00:22:42,419 --> 00:22:42,950
the name

420
00:22:42,950 --> 00:22:46,700
have a car dealer and it you can tell
it's not quite correct

421
00:22:46,700 --> 00:22:50,980
how did you get this way we're gonna
play a little unique ok yes I hear

422
00:22:50,980 --> 00:22:54,240
we're gonna in code that unico 3 into

423
00:22:54,240 --> 00:22:58,220
a byte string using are known in calling
a few feet of 52

424
00:22:58,220 --> 00:23:02,400
and we're gonna end up with this biting
sequence so you can see here each

425
00:23:02,400 --> 00:23:03,150
character

426
00:23:03,150 --> 00:23:07,230
up above is matte color maps to the byte
string representation a bit below

427
00:23:07,230 --> 00:23:10,890
we did some extensive research on the
sequence of bytes

428
00:23:10,890 --> 00:23:14,350
and we found that in a different
encoding those three characters

429
00:23:14,350 --> 00:23:17,580
the street bites actually represent a
single character

430
00:23:17,580 --> 00:23:21,460
using utf8 so just to clear clarify

431
00:23:21,460 --> 00:23:25,669
you have this bites ring with those
three characters those bike thanks

432
00:23:25,669 --> 00:23:30,030
sequences that if you decode using utf8
will actually give you

433
00:23:30,030 --> 00:23:33,870
a much more reasonable looking name for
an auto dealer

434
00:23:33,870 --> 00:23:37,770
to recap somebody had a smart apostrophe

435
00:23:37,770 --> 00:23:42,090
basically that day encoded using utf8
into the following

436
00:23:42,090 --> 00:23:45,860
bytes and then somebody else or maybe
even the same person

437
00:23:45,860 --> 00:23:49,210
miss decoded it using the wrong encoding
and gave us

438
00:23:49,210 --> 00:23:53,820
the three garbage characters so this is
how much you back key is born

439
00:23:53,820 --> 00:23:57,860
and there are a couple ways to fix it
actually one thing you can't do

440
00:23:57,860 --> 00:24:02,270
is to change the encoding that you're
using TTF 8 because you know that your

441
00:24:02,270 --> 00:24:06,710
the rest of your source data is CP 2 of
52 so what you could do is maybe keep

442
00:24:06,710 --> 00:24:07,130
track

443
00:24:07,130 --> 00:24:10,990
have known troublesome byte sequences
like the ones that we have here

444
00:24:10,990 --> 00:24:14,179
and just can't keep track of them into a
manual replacement

445
00:24:14,179 --> 00:24:19,159
with the biting reputation that's
correct in CP 12:52 for that character

446
00:24:19,159 --> 00:24:22,510
if you do this so your list is only
gonna grow along your application runs

447
00:24:22,510 --> 00:24:23,029
and

448
00:24:23,029 --> 00:24:26,850
a huge pain to maintain likely for you

449
00:24:26,850 --> 00:24:30,919
there's a library called Python ftfy
fixes text for you

450
00:24:30,919 --> 00:24:35,770
and it fixes muddy backing so it has its
own conversion tables and uses

451
00:24:35,770 --> 00:24:37,470
heuristics to process tax

452
00:24:37,470 --> 00:24:41,000
and try to clean up any Mota packy
strings that you have

453
00:24:41,000 --> 00:24:44,400
all you have to do is pass it that much
you back aid you could object

454
00:24:44,400 --> 00:24:47,840
run fixed text on it an offer you back
its best guess for what

455
00:24:47,840 --> 00:24:51,320
cleaned up more correction should be

456
00:24:51,320 --> 00:24:54,960
it's not a perfect labor is still under
active development but it really good we

457
00:24:54,960 --> 00:24:57,230
use it in our production code it saved
us

458
00:24:57,230 --> 00:25:01,270
a great deal of time so one more issue

459
00:25:01,270 --> 00:25:04,820
and that's where you need to store data
using a target in codeine

460
00:25:04,820 --> 00:25:08,929
that can handle the characters in your
source in coding

461
00:25:08,929 --> 00:25:12,240
so what do I mean by that let's say yes
some source data

462
00:25:12,240 --> 00:25:16,110
thats utf8 rights coming in from Twitter
or something and they're snowmen and

463
00:25:16,110 --> 00:25:18,080
their people like to write about snowman

464
00:25:18,080 --> 00:25:22,620
and you're told you need to store this
data in a CP 12:52 database name it my

465
00:25:22,620 --> 00:25:23,580
sequel

466
00:25:23,580 --> 00:25:28,659
and that target database is out of your
control you can change the encoding your

467
00:25:28,659 --> 00:25:31,460
told you need to store the state NCP
12:52

468
00:25:31,460 --> 00:25:35,309
wall the problem is CP 12:52 you can't
handle snowman

469
00:25:35,309 --> 00:25:39,630
I short up some kinda crazy hack which
its not advised so

470
00:25:39,630 --> 00:25:42,750
at the application level what are your
options well

471
00:25:42,750 --> 00:25:46,000
the default behavior when you see a
snowman

472
00:25:46,000 --> 00:25:50,929
or another character and you encode it
into an encoding that can handle that

473
00:25:50,929 --> 00:25:51,900
character

474
00:25:51,900 --> 00:25:55,900
is this strict behavior and what Python
does

475
00:25:55,900 --> 00:26:00,029
using the strict behavior is it just
raises stack trace right it airs out to

476
00:26:00,029 --> 00:26:01,059
you could use this

477
00:26:01,059 --> 00:26:05,370
and write some fancy code that fires up
an email and says hey we found snowman

478
00:26:05,370 --> 00:26:08,150
in the source data we can handle this
fix your source data

479
00:26:08,150 --> 00:26:11,640
or whatever but that's not super
flexible so pipe and a few other options

480
00:26:11,640 --> 00:26:13,289
you have other options and you know

481
00:26:13,289 --> 00:26:17,309
any any character encoding process seen
so one option is to ignore

482
00:26:17,309 --> 00:26:21,860
those characters right processing your
data moving it to CP 12:52

483
00:26:21,860 --> 00:26:26,260
you say when I see a snowman move along
everything's great here

484
00:26:26,260 --> 00:26:29,500
you know just ignored the problem is
then your target data

485
00:26:29,500 --> 00:26:33,559
is miss seen those characters and you
might end up with some really funky

486
00:26:33,559 --> 00:26:34,860
looking output data

487
00:26:34,860 --> 00:26:38,110
arm so I a slightly more graceful way to
handle it

488
00:26:38,110 --> 00:26:41,620
is to replace those characters with the
circuit character

489
00:26:41,620 --> 00:26:44,860
just a placeholder so you processing
your text you see snowman

490
00:26:44,860 --> 00:26:48,120
he say I can't do snowman in CP 12:52

491
00:26:48,120 --> 00:26:51,909
but I'm a drop a marker here so the
person who comes after me recognizes

492
00:26:51,909 --> 00:26:53,600
there was a character there

493
00:26:53,600 --> 00:26:57,059
that couldn't be properly encoded using
the target in coding

494
00:26:57,059 --> 00:27:01,240
it's important with both and ignore or
replace operation

495
00:27:01,240 --> 00:27:04,240
to know that these are lost the
operations thats RBS

496
00:27:04,240 --> 00:27:08,730
by on if you may be able to upgrade your
database utf8 in the future then maybe

497
00:27:08,730 --> 00:27:10,940
it's worth keeping the source data
around

498
00:27:10,940 --> 00:27:15,000
so that you can properly encoded in the
future

499
00:27:15,000 --> 00:27:18,380
for that we've server at a time and come
to the universe talk

500
00:27:18,380 --> 00:27:21,929
we hope that we've covered the basics
well enough for you to do more research

501
00:27:21,929 --> 00:27:25,090
but also to make your life a little
easier even now

502
00:27:25,090 --> 00:27:28,120
wanna thank other fine people for
helping us with our talk

503
00:27:28,120 --> 00:27:32,179
and I I don't know how to refer
questions but we do have our site up

504
00:27:32,179 --> 00:27:33,230
online right now

505
00:27:33,230 --> 00:27:36,470
sometimes gonna blow through these you
can look them up yourself and do some

506
00:27:36,470 --> 00:27:37,350
further reading

507
00:27:37,350 --> 00:27:40,429
by our side her up and feel free to
contact us through these channels if you

508
00:27:40,429 --> 00:27:41,340
have any questions

509
00:27:41,340 --> 00:27:48,340
thank you very much

510
00:27:51,190 --> 00:27:52,929
-10 for like one question

511
00:27:52,929 --> 00:27:56,190
okay

512
00:27:56,190 --> 00:28:01,029
okay here you

513
00:28:01,029 --> 00:28:07,740
yep I country so Python 3

514
00:28:07,740 --> 00:28:11,120
kinda flipped everything upside down a
little bit and reverses the rolls right

515
00:28:11,120 --> 00:28:14,529
and we don't have enough time to give
you any kind of actual grasp on that

516
00:28:14,529 --> 00:28:19,710
on again adds 2002 2012 talk actually
deals with a pretty well and explains

517
00:28:19,710 --> 00:28:20,039
that

518
00:28:20,039 --> 00:28:23,700
there some other talks go to a pipe
video I'm and look for the unico talks

519
00:28:23,700 --> 00:28:25,389
and it will give you a good
understanding a

520
00:28:25,389 --> 00:28:31,320
Python 3 good yep

521
00:28:31,320 --> 00:28:34,760
by order marks right so

522
00:28:34,760 --> 00:28:38,480
summing Cody means I UT F-sixteen

523
00:28:38,480 --> 00:28:44,149
for example I will drop by by at the
very beginning evolve attacks to tell

524
00:28:44,149 --> 00:28:48,389
tell you I big endian little and the end
and so

525
00:28:48,389 --> 00:28:54,029
I I don't actually I can't go super into
detail on that right now again there's

526
00:28:54,029 --> 00:28:57,750
some other talks that do get into the
details on it and frankly I've avoided

527
00:28:57,750 --> 00:29:00,940
encodings where that was an issue but
I'm not used to be a real big issue in

528
00:29:00,940 --> 00:29:02,750
kinda UT F-sixteen was

529
00:29:02,750 --> 00:29:06,500
the you know de facto you know coding
coding so you know what's nice about

530
00:29:06,500 --> 00:29:09,519
utf8 is that it doesn't require that by
tournament because

531
00:29:09,519 --> 00:29:16,519
a uses it just because an intense the
the from future import

532
00:29:21,450 --> 00:29:25,769
unit code literals I'll we haven't
actually used that

533
00:29:25,769 --> 00:29:29,870
arm I think had yeah I better not a
better not speak gotta turn I've read

534
00:29:29,870 --> 00:29:31,059
about it a little bit but

535
00:29:31,059 --> 00:29:34,799
RR the stuff we've been doing recently
has been not required to

536
00:29:34,799 --> 00:29:37,769
sup great thank you

