1
00:00:07,430 --> 00:00:07,799
a good

2
00:00:07,799 --> 00:00:12,790
ready okay

3
00:00:12,790 --> 00:00:16,850
hello everybody I'm up next we've got
Catherine John Moore he's going to give

4
00:00:16,850 --> 00:00:17,869
us a performance

5
00:00:17,869 --> 00:00:21,189
accuracy with you at the top I've been
scraping my PC

6
00:00:21,189 --> 00:00:28,189
please welcome our hi everybody

7
00:00:29,210 --> 00:00:33,610
I'm here for papon scraping showdown
hopefully you are to you if not please

8
00:00:33,610 --> 00:00:35,230
see the directory in the hallway

9
00:00:35,230 --> 00:00:38,640
my name is Catherine Jarmo also known
fondly

10
00:00:38,640 --> 00:00:42,829
as KJM on a little bit about me

11
00:00:42,829 --> 00:00:45,920
I've been using scrapers since 2010

12
00:00:45,920 --> 00:00:50,309
after sheesh inspired me I went to his
QB tutorial

13
00:00:50,309 --> 00:00:54,129
if you get bored of this talk is giving
a rather fun talk with Karen over a

14
00:00:54,129 --> 00:00:55,129
couple rooms down

15
00:00:55,129 --> 00:01:01,940
evidently my Google delay

16
00:01:01,940 --> 00:01:08,920
is a little delayed I a little bit more
about me as I am the pie ladies

17
00:01:08,920 --> 00:01:13,869
cofounder one the pile is cofounder I'm
happy to see a lot of Pi ladies here

18
00:01:13,869 --> 00:01:14,840
with me today

19
00:01:14,840 --> 00:01:19,049
chided

20
00:01:19,049 --> 00:01:26,049
move us along apologies

21
00:01:34,760 --> 00:01:37,430
evidently everybody's on the same
network imagine that

22
00:01:37,430 --> 00:01:44,430
I am let me a if I can

23
00:02:00,500 --> 00:02:07,380
and

24
00:02:07,380 --> 00:02:14,380
maybe

25
00:02:17,620 --> 00:02:24,620
apologies again

26
00:02:33,480 --> 00:02:40,480
well mack you have failed me

27
00:02:55,080 --> 00:03:02,080
much there's a better way to go about
this

28
00:03:12,819 --> 00:03:17,020
them

29
00:03:17,020 --> 00:03:22,010
basher

30
00:03:22,010 --> 00:03:22,910
Siam you 1

31
00:03:22,910 --> 00:03:29,910
K

32
00:04:03,870 --> 00:04:05,349
right

33
00:04:05,349 --> 00:04:08,040
see if I have better luck year

34
00:04:08,040 --> 00:04:15,040
apologies again

35
00:04:36,090 --> 00:04:38,069
yeah

36
00:04:38,069 --> 00:04:45,069
alright let's get started here apologies
again for

37
00:04:45,379 --> 00:04:49,409
that delay hopefully I can speed it up a
bit

38
00:04:49,409 --> 00:04:56,409
and I get it going okay so I have a pile
is cofounder

39
00:04:56,969 --> 00:05:00,300
I am relocating to berlin in a couple of
days

40
00:05:00,300 --> 00:05:03,879
so if you live in Berlin or know
somebody who I should meet please come

41
00:05:03,879 --> 00:05:04,490
say hi

42
00:05:04,490 --> 00:05:09,569
so why scrape the web on this is
becoming more and more of a question

43
00:05:09,569 --> 00:05:12,699
there's a lot of public API's there's a
lot serve

44
00:05:12,699 --> 00:05:16,699
rest or Jason enabled endpoints both
public

45
00:05:16,699 --> 00:05:19,789
and not so public but easily found

46
00:05:19,789 --> 00:05:23,559
upon investigating website there's also
a lot of well-maintained

47
00:05:23,559 --> 00:05:26,990
open source API libraries showed those

48
00:05:26,990 --> 00:05:30,029
you know again allow us to scrape
Twitter Facebook

49
00:05:30,029 --> 00:05:33,800
I'm whatever it is we're attempting to
use I'm without

50
00:05:33,800 --> 00:05:37,379
a really using than traditional
stripping libraries

51
00:05:37,379 --> 00:05:40,550
i'm for Python selenium is still your
best bet

52
00:05:40,550 --> 00:05:43,860
if you need anything that does
JavaScript interaction

53
00:05:43,860 --> 00:05:48,459
or that's loaded after the DOM so you're
kind of a little bit shackled there

54
00:05:48,459 --> 00:05:50,719
there's plenty of node libraries out
there but

55
00:05:50,719 --> 00:05:53,909
in Python that's really our are you have

56
00:05:53,909 --> 00:05:57,159
and albeit

57
00:05:57,159 --> 00:06:00,649
with all those caveats I still think
that there's a lot of sites 3 could

58
00:06:00,649 --> 00:06:03,709
build a traditional scraper and scrape
content that way

59
00:06:03,709 --> 00:06:07,479
and I still find it very fun to build
those for my own use

60
00:06:07,479 --> 00:06:11,300
so what this talk is gonna cover I'm
gonna look at

61
00:06:11,300 --> 00:06:14,839
a different performance with an LX
Malvern and beautiful soup

62
00:06:14,839 --> 00:06:18,050
I'll go and to a little bit more why I

63
00:06:18,050 --> 00:06:21,069
narrowed it down I'm going to

64
00:06:21,069 --> 00:06:24,990
talk about finding elements with
selenium sell a lot of us who've you

65
00:06:24,990 --> 00:06:26,050
selenium there's

66
00:06:26,050 --> 00:06:29,759
many options for finding elements I'm
gonna talk about which is the fastest

67
00:06:29,759 --> 00:06:34,409
and I'm gonna take a look at scrapie or
scrap hi I'm not quite sure the

68
00:06:34,409 --> 00:06:35,349
pronunciation

69
00:06:35,349 --> 00:06:38,639
and see how fast we can go with Python
and scraping the web

70
00:06:38,639 --> 00:06:43,330
so a bit of a disclaimer when I first
was putting together a test for this

71
00:06:43,330 --> 00:06:46,849
I want to screw use quite a lot of
stripping libraries

72
00:06:46,849 --> 00:06:50,199
when I found as I begin to look at it is
a lot of them are using similar

73
00:06:50,199 --> 00:06:51,370
dependencies

74
00:06:51,370 --> 00:06:54,680
it so I decided that it might be but
I've best used to hone in

75
00:06:54,680 --> 00:06:58,469
on some of the most popular ones and
most widely used ones

76
00:06:58,469 --> 00:07:05,279
which is what led me to LX Intel and
beautiful suit I also in this I kinda

77
00:07:05,279 --> 00:07:07,069
wanted to find some broken pages

78
00:07:07,069 --> 00:07:10,490
I've been scraping using LX and now for
some years now and

79
00:07:10,490 --> 00:07:15,019
it often would happen to me where I come
across a page where r beautiful soup was

80
00:07:15,019 --> 00:07:17,620
truly my only option to accurately parce
page

81
00:07:17,620 --> 00:07:20,729
I think html5 is changing this landscape

82
00:07:20,729 --> 00:07:24,969
and hopefully allowing us to have more
standardized web content which allows us

83
00:07:24,969 --> 00:07:26,019
to scrape the web

84
00:07:26,019 --> 00:07:29,370
utilizing the elementary API's and other
things

85
00:07:29,370 --> 00:07:34,789
similar to that if you find of course
broken pages beautiful soup an html5

86
00:07:34,789 --> 00:07:35,599
live also have

87
00:07:35,599 --> 00:07:40,399
quite a lot of helpers for scraping you
know truly broken pages that don't

88
00:07:40,399 --> 00:07:41,759
follow any sort of

89
00:07:41,759 --> 00:07:46,589
uniformity attacks and all of my code
for this talk is available at my get

90
00:07:46,589 --> 00:07:47,050
home

91
00:07:47,050 --> 00:07:50,919
so I created a repository I believe
called web scraping

92
00:07:50,919 --> 00:07:53,930
speed comparison and

93
00:07:53,930 --> 00:07:57,339
you can please forget downloaded am play
around with it

94
00:07:57,339 --> 00:08:01,979
prove me wrong with my own test I'm so I
wanted to compare

95
00:08:01,979 --> 00:08:06,079
LX Nankivil soup a lot of times these
are you know the commonly in most

96
00:08:06,079 --> 00:08:07,169
popular used

97
00:08:07,169 --> 00:08:11,059
on DU's distinctly different methods to
unpacking parse

98
00:08:11,059 --> 00:08:14,209
HTML so I wanted to kind of take a look
at those methods

99
00:08:14,209 --> 00:08:19,349
on and both of them I find to be
tremendously accurate with the right

100
00:08:19,349 --> 00:08:21,110
level of detail so

101
00:08:21,110 --> 00:08:25,399
I feel like a lot of it is up to the
developer the onus is on you

102
00:08:25,399 --> 00:08:29,539
to kinda write your scraper in such a
way that your accurately finding the day

103
00:08:29,539 --> 00:08:29,889
a

104
00:08:29,889 --> 00:08:34,419
but I find them fairly easy to
manipulate for this purpose and

105
00:08:34,419 --> 00:08:39,469
l/xl utilizes both X pass and CSS
selects I decided to compare that is

106
00:08:39,469 --> 00:08:42,469
me myself being a developer being lazy

107
00:08:42,469 --> 00:08:46,480
a lot of times are just rely on CFS
select rather than write out the entire

108
00:08:46,480 --> 00:08:47,269
expat

109
00:08:47,269 --> 00:08:54,269
and I wanted to see whether I was losing
a lot of time

110
00:08:54,990 --> 00:08:59,459
okay so what was my methodology I'm
first I wrote accurate scrapers um

111
00:08:59,459 --> 00:09:03,720
as best I could and then I try to find
similar ways to parse it so with a lot

112
00:09:03,720 --> 00:09:05,480
of my functions I tried to follow

113
00:09:05,480 --> 00:09:08,660
a similar method find and search

114
00:09:08,660 --> 00:09:15,140
said that I could continue I to compared
the library is rather than my own code

115
00:09:15,140 --> 00:09:18,350
I'm fairly certain I could have written
the sparse is to be faster

116
00:09:18,350 --> 00:09:21,959
by employing different fast message
methods at the library

117
00:09:21,959 --> 00:09:25,709
but I found that maybe this might be the
most accurate way

118
00:09:25,709 --> 00:09:30,839
then I used I'm see profile & key stats
to kinda analyze how much it took

119
00:09:30,839 --> 00:09:35,910
for each function to run um and then I
aidid over a number of trials

120
00:09:35,910 --> 00:09:40,370
ranging from 10 to 500 so the first
thing that I decide to do is they want

121
00:09:40,370 --> 00:09:42,100
to strip the NHL scores

122
00:09:42,100 --> 00:09:46,089
I'm an avid hockey fan and were about to
enter playoff

123
00:09:46,089 --> 00:09:50,209
and we're in Canada so I figured I might
be amongst hockey fanatics

124
00:09:50,209 --> 00:09:53,790
and so I went to on their scores page

125
00:09:53,790 --> 00:09:57,209
and I personally and Big Twins fan

126
00:09:57,209 --> 00:10:01,549
so I wanted to see how miglin's were
gonna do in a playoff

127
00:10:01,549 --> 00:10:05,000
this is the only code I'll show you n
apologies again for trying to fit it all

128
00:10:05,000 --> 00:10:05,970
in stride

129
00:10:05,970 --> 00:10:10,110
again the repos up on my get her back
page am on but basically you can see

130
00:10:10,110 --> 00:10:10,610
here

131
00:10:10,610 --> 00:10:13,779
I have my LX now with XPath LX now with
CSS

132
00:10:13,779 --> 00:10:17,309
and beautiful soup and I attempted to
employ

133
00:10:17,309 --> 00:10:21,529
similar ways love on you know I'm
packing and wrapping the content

134
00:10:21,529 --> 00:10:25,740
finding the scores body then finding
those game boxes and then going within

135
00:10:25,740 --> 00:10:27,059
the columns to find

136
00:10:27,059 --> 00:10:30,360
but the key names and the scores

137
00:10:30,360 --> 00:10:34,140
and hears it were my results so as you
can see

138
00:10:34,140 --> 00:10:37,269
LX in our next stop was a clear winner
here on

139
00:10:37,269 --> 00:10:40,480
it was away under even point 06

140
00:10:40,480 --> 00:10:43,939
per run as well as beautiful soup was be

141
00:10:43,939 --> 00:10:47,069
took the longest it was up to nearly
point2 for

142
00:10:47,069 --> 00:10:52,510
seconds per run on you can see that elec
smell with CSS was just a close second

143
00:10:52,510 --> 00:10:53,439
particularly

144
00:10:53,439 --> 00:10:57,209
as the averages got a higher

145
00:10:57,209 --> 00:11:01,149
and we could take a little bit have a
look here at why and where the speed

146
00:11:01,149 --> 00:11:02,220
might come from

147
00:11:02,220 --> 00:11:06,610
to PCL XL with expat has 238 function
calls

148
00:11:06,610 --> 00:11:11,420
a far below the 280,000 that beautiful
soup average

149
00:11:11,420 --> 00:11:15,059
so we can start to see maybe on this is
where some up to speed up

150
00:11:15,059 --> 00:11:20,329
x-pac is coming into play again these
buried by Ryan up but I didn't see a

151
00:11:20,329 --> 00:11:23,620
large disparity amongst friends

152
00:11:23,620 --> 00:11:26,929
um and so then inaccuracy review all
love

153
00:11:26,929 --> 00:11:32,019
the different a scrapers were able to
accurately find all the game scores

154
00:11:32,019 --> 00:11:35,620
and just so that you can run these as
well in the

155
00:11:35,620 --> 00:11:41,709
repository I also included this source
the initial pages I was scraping

156
00:11:41,709 --> 00:11:45,959
so the next thing I decided to do is I
have benefit e-commerce background as

157
00:11:45,959 --> 00:11:46,630
well

158
00:11:46,630 --> 00:11:51,569
and e-commerce site are notoriously
messy and so I decided to scrape Amazon

159
00:11:51,569 --> 00:11:52,439
deals

160
00:11:52,439 --> 00:11:56,089
so I can get my di love the day in my
email but what about these Lightning

161
00:11:56,089 --> 00:11:57,670
Deals across the bottom

162
00:11:57,670 --> 00:12:02,829
what I wanted to do is grab the title
%uh the link and the price

163
00:12:02,829 --> 00:12:06,929
and what I found in running it is again
LX Mel with XPath

164
00:12:06,929 --> 00:12:10,799
was the winner but we see here that
depending on

165
00:12:10,799 --> 00:12:15,149
the site content and how quickly can be
parsed beautiful soup was only several

166
00:12:15,149 --> 00:12:16,769
hundredths of a second

167
00:12:16,769 --> 00:12:21,589
slower cell we can start to see hey you
know what all these are pretty fast

168
00:12:21,589 --> 00:12:22,510
options

169
00:12:22,510 --> 00:12:25,939
on yes l/xl with XPath is the fastest

170
00:12:25,939 --> 00:12:30,370
we can start to see that depending on
the page we're gonna have a variety of

171
00:12:30,370 --> 00:12:31,889
time

172
00:12:31,889 --> 00:12:36,120
but again when I looked at the function
calls I saw just far less overhead

173
00:12:36,120 --> 00:12:40,209
with expat I'm even then with LX now
using CSS

174
00:12:40,209 --> 00:12:43,290
select

175
00:12:43,290 --> 00:12:48,199
so inaccuracy review this oddly enough
beautiful soup was not able to properly

176
00:12:48,199 --> 00:12:51,589
parse using the same sort of sin taxes
others

177
00:12:51,589 --> 00:12:55,610
I actually was having a hard time even
getting to that part a page without

178
00:12:55,610 --> 00:12:57,589
using a whole family tree

179
00:12:57,589 --> 00:13:02,689
crawl and so what I determined are what
I did is I modified it so it find the

180
00:13:02,689 --> 00:13:04,179
top deal so it could be

181
00:13:04,179 --> 00:13:07,540
at least comparative I wasn't going to
sit there and compare

182
00:13:07,540 --> 00:13:11,939
you know twenty to thirty lines a
beautiful see you with 512 Velux now

183
00:13:11,939 --> 00:13:16,400
but this is actually interesting fine
for me site that I checked

184
00:13:16,400 --> 00:13:19,919
the third and last case study that I did
in terms of scraping

185
00:13:19,919 --> 00:13:23,319
was I looked at New York Times mobile
site I definitely wanted to do mobile

186
00:13:23,319 --> 00:13:24,880
site because mobile sites

187
00:13:24,880 --> 00:13:28,319
as we all know are generally more
lightweight they load faster

188
00:13:28,319 --> 00:13:33,049
on they usually have less JavaScript and
other junk running on the page

189
00:13:33,049 --> 00:13:36,409
and what I did was I grab the headline
the link and the blurb if it was

190
00:13:36,409 --> 00:13:37,299
available

191
00:13:37,299 --> 00:13:42,380
at the New York Times mobile home page
and again I found

192
00:13:42,380 --> 00:13:46,159
that we had tremendous speed with all
libraries if you can't see from across

193
00:13:46,159 --> 00:13:46,850
the back

194
00:13:46,850 --> 00:13:50,689
even beautiful soup is clocking in at
four-and-a-half hundreds

195
00:13:50,689 --> 00:13:54,459
a second um but l/xl with XPath was just

196
00:13:54,459 --> 00:13:58,750
super super speedy

197
00:13:58,750 --> 00:14:03,380
and what I found here again with the
average function calls XPath with a

198
00:14:03,380 --> 00:14:06,990
little bit more than Iowa had expected
given the other runs

199
00:14:06,990 --> 00:14:11,089
but regardless on it's still was am

200
00:14:11,089 --> 00:14:16,459
much fewer calls than the others and
again in accuracy they all sound 17

201
00:14:16,459 --> 00:14:17,299
articles

202
00:14:17,299 --> 00:14:20,890
and there was an all set at the bottom
I'm assuming New York Times uses it for

203
00:14:20,890 --> 00:14:22,650
some sorta styled writer

204
00:14:22,650 --> 00:14:27,429
cell LX a mallet expat is the clear
winner here in terms of speed

205
00:14:27,429 --> 00:14:30,429
on but at the end of the day it's really
not by much

206
00:14:30,429 --> 00:14:34,679
so I would again a I would caution
against saying something like beautiful

207
00:14:34,679 --> 00:14:37,039
super slow that's just not true

208
00:14:37,039 --> 00:14:41,650
and I would caution against saying l/xl
expat is the fastest thing in the world

209
00:14:41,650 --> 00:14:46,130
but it is pretty fast and if you're
looking at scrubbing quite a lot of data

210
00:14:46,130 --> 00:14:49,539
it would definitely be worth
investigating right so I'm gonna take a

211
00:14:49,539 --> 00:14:50,760
look at selenium

212
00:14:50,760 --> 00:14:54,020
arm selenium by far if you're using
Python

213
00:14:54,020 --> 00:14:58,549
is the best for page interactions or
after download elements

214
00:14:58,549 --> 00:15:02,640
especially anything that has like login
flows and things like that I find

215
00:15:02,640 --> 00:15:08,000
it's just really useful arm flame also
gives you a whole lot of ways to find

216
00:15:08,000 --> 00:15:09,569
elements on the page

217
00:15:09,569 --> 00:15:14,370
and I wonder to myself when I coats lady
in things I mean MRT losing so much time

218
00:15:14,370 --> 00:15:16,490
loading a browser including three things

219
00:15:16,490 --> 00:15:20,459
what's going to be the fastest in terms
of finding elements

220
00:15:20,459 --> 00:15:24,260
and so I'm gonna compare I'm find
element by tag name

221
00:15:24,260 --> 00:15:29,260
finalement bike last name and find
element by expect

222
00:15:29,260 --> 00:15:33,679
there are others to compare but I find
that I used to use the most

223
00:15:33,679 --> 00:15:37,089
so I decide to go to yahoo dot com and I
wanted to find

224
00:15:37,089 --> 00:15:41,480
on the search box and I wanted to find
this little trending now section

225
00:15:41,480 --> 00:15:44,549
I'm its training across yeah I guess I
was curious as to

226
00:15:44,549 --> 00:15:48,319
what was there what I thought is maybe
this might be a good start script

227
00:15:48,319 --> 00:15:52,079
for going about and searching different
a

228
00:15:52,079 --> 00:15:56,409
search sites and seeing what they came
up with how many results are similar

229
00:15:56,409 --> 00:15:59,669
or different this just will compared
find now

230
00:15:59,669 --> 00:16:03,089
and what I found is that again we're
dealing with

231
00:16:03,089 --> 00:16:06,929
a really 100 for the second difference I
found that with the

232
00:16:06,929 --> 00:16:12,010
shorter runs CSS sometimes be expat this
is why the times that it did sell

233
00:16:12,010 --> 00:16:15,789
I wanted to show that and but still we
see the XPath

234
00:16:15,789 --> 00:16:19,179
over the average have many runs arm
comes

235
00:16:19,179 --> 00:16:23,419
clocks in as the fastest and tagname
actually ended up being the slowest

236
00:16:23,419 --> 00:16:26,699
which was surprising to me I assumed
kind of that tag name

237
00:16:26,699 --> 00:16:29,850
used expat underneath the covers on but

238
00:16:29,850 --> 00:16:33,220
that might not be the case if somebody
works on selenium or

239
00:16:33,220 --> 00:16:36,220
understand selenium better than I i and
maybe you can

240
00:16:36,220 --> 00:16:41,500
best explain this on but when I looked
at the function calls I found an expat

241
00:16:41,500 --> 00:16:45,610
had quite a lot more than I expected
this probably has to do with the fact

242
00:16:45,610 --> 00:16:46,899
that selenium is

243
00:16:46,899 --> 00:16:50,470
most likely using a rendering engine
more similar to the browser

244
00:16:50,470 --> 00:16:55,569
rest I was CSS had a very low number a
function calls in comparison

245
00:16:55,569 --> 00:16:58,760
on that made me think that if you're
running quite a lot of selenium maybe

246
00:16:58,760 --> 00:17:01,209
CSS is going to be the best way

247
00:17:01,209 --> 00:17:06,250
tag name here was the clear loser I'm
CSS an XPath are both great

248
00:17:06,250 --> 00:17:09,630
tag is clearly slower and with more
calls but

249
00:17:09,630 --> 00:17:13,179
similarly to my find with web scraping
libraries

250
00:17:13,179 --> 00:17:17,949
it wasn't that huge a difference and
again you wanna think about

251
00:17:17,949 --> 00:17:21,339
what you're comfortable with what your
team is comfortable with and what is

252
00:17:21,339 --> 00:17:22,459
readable to you

253
00:17:22,459 --> 00:17:26,260
and use you know what makes the most
sense for your script

254
00:17:26,260 --> 00:17:29,679
so I want in investigate scrapie

255
00:17:29,679 --> 00:17:34,730
on it uses l/xl XPath to find elements
or as they call them within the library

256
00:17:34,730 --> 00:17:39,169
items and it uses twisted for a
synchronous crawling

257
00:17:39,169 --> 00:17:42,330
I'm so to me arm it seemed

258
00:17:42,330 --> 00:17:45,510
that it was going to be really speedy
also

259
00:17:45,510 --> 00:17:49,210
scrapie i've seen. evolve a lot over the
past two years I've kinda been

260
00:17:49,210 --> 00:17:52,399
following it out watching it grow and
its

261
00:17:52,399 --> 00:17:56,840
just become quite powerful in terms of
crawling inspiring the web

262
00:17:56,840 --> 00:18:01,700
if you haven't used it yet I you know
cannot encourage you enough

263
00:18:01,700 --> 00:18:05,419
to go about building your own crawler
and they just have a lot of really

264
00:18:05,419 --> 00:18:08,190
robust functionality and helpers for you

265
00:18:08,190 --> 00:18:11,279
and so with our speed knowledge I was
wondering

266
00:18:11,279 --> 00:18:15,380
how fast can we get

267
00:18:15,380 --> 00:18:19,570
cell what I wanted to do is I was gonna
Creek Google with pagination

268
00:18:19,570 --> 00:18:23,289
I'm for search results within the search
result I was

269
00:18:23,289 --> 00:18:27,890
fine be titled the blurb and the link am
I didn't worry about saving it to

270
00:18:27,890 --> 00:18:30,919
discover I don't want any right setting
up my speed tests

271
00:18:30,919 --> 00:18:35,140
so again this can add some time
depending on your script

272
00:18:35,140 --> 00:18:39,460
so I Google Python because about I

273
00:18:39,460 --> 00:18:43,659
and so here's a bit of my stats and you
can see my see profile tabs at the

274
00:18:43,659 --> 00:18:46,330
bottom but I was having to use a command
line

275
00:18:46,330 --> 00:18:49,679
caller from within the scope the library
to get it running

276
00:18:49,679 --> 00:18:54,370
so but you can see I'm the item scrapes
count is 306

277
00:18:54,370 --> 00:18:57,580
if you look at the start time compared
to the end time

278
00:18:57,580 --> 00:19:01,330
we're talking about slightly like a
shave over

279
00:19:01,330 --> 00:19:04,659
three seconds to get 306

280
00:19:04,659 --> 00:19:08,600
result cell escaping Google

281
00:19:08,600 --> 00:19:12,740
the spider was averaging almost a
hundred result a second or around about

282
00:19:12,740 --> 00:19:15,390
sometimes little over sometimes a little
under

283
00:19:15,390 --> 00:19:18,500
I'm to me that seem tremendously fast
and it was really

284
00:19:18,500 --> 00:19:22,909
exciting to see how powerful it could be
also Google hates me

285
00:19:22,909 --> 00:19:25,919
cell II caution you against

286
00:19:25,919 --> 00:19:31,429
running the script at home during
off-hours I was captured it to death

287
00:19:31,429 --> 00:19:35,210
on but I find that if you run it during
you know the busy time for the day in

288
00:19:35,210 --> 00:19:37,340
the morning hours whatever your time
zone is

289
00:19:37,340 --> 00:19:40,799
I'm maybe Google hate you left a lot of
times okie get through

290
00:19:40,799 --> 00:19:44,470
up to you at 340 results and about 300

291
00:19:44,470 --> 00:19:48,529
sixty mark or whichever one with twisted
finished

292
00:19:48,529 --> 00:19:52,899
bill last I would get captured

293
00:19:52,899 --> 00:19:56,159
and also escapee has a bunch a different
tools

294
00:19:56,159 --> 00:20:00,070
very similar to what we saw in the
mechanized functionality for those are

295
00:20:00,070 --> 00:20:01,730
you that are familiar with the
mechanized

296
00:20:01,730 --> 00:20:06,659
library I'm to get around capture blocks
you can use different user agent strings

297
00:20:06,659 --> 00:20:10,309
you can use different IP's and other
things like that so

298
00:20:10,309 --> 00:20:15,640
on I for this test I wanted to rather
then see how quickly I could fool Google

299
00:20:15,640 --> 00:20:19,000
I wanted to see how quickly I can get
the scraper running

300
00:20:19,000 --> 00:20:25,059
cell but its its easily for couple or to
write your own and use some love

301
00:20:25,059 --> 00:20:29,350
their logic to use great Google even
faster and at more length during

302
00:20:29,350 --> 00:20:33,480
of our so in conclusion

303
00:20:33,480 --> 00:20:36,929
on L XML using XPath is the clear winner

304
00:20:36,929 --> 00:20:42,320
when it comes to speed i'm for
readability inaccuracy though both

305
00:20:42,320 --> 00:20:46,039
in the code and the content that you
scrape you know it's really

306
00:20:46,039 --> 00:20:49,230
the time difference was not as amazing
as I thought

307
00:20:49,230 --> 00:20:53,870
it was amazing enough that if you're
parsing thousands of web sites

308
00:20:53,870 --> 00:20:56,980
it's probably gonna make a difference to
you but if you're just

309
00:20:56,980 --> 00:21:00,200
writing a scare at home for your
favorite restaurant or

310
00:21:00,200 --> 00:21:04,159
on to finding local Deals near you or
whatever it might be

311
00:21:04,159 --> 00:21:08,710
arm then I don't think there's a big
difference and it's gonna end up being

312
00:21:08,710 --> 00:21:12,149
you know what is easiest for you to
install with easiest for your team to

313
00:21:12,149 --> 00:21:12,880
use

314
00:21:12,880 --> 00:21:17,789
and your code again might vary so there
are ways to speed up beautiful soup

315
00:21:17,789 --> 00:21:18,480
depending

316
00:21:18,480 --> 00:21:22,309
on the way that the pages parse on and I
would advise using those

317
00:21:22,309 --> 00:21:26,070
if you are set with like a Windows
operating system are something else

318
00:21:26,070 --> 00:21:28,590
where LX now becomes a big pain

319
00:21:28,590 --> 00:21:33,330
in the rear to install on MN if X
Factor's too confusing or limiting

320
00:21:33,330 --> 00:21:37,220
if if you're really into Webster being a
strongly encourage your expat I'm it's

321
00:21:37,220 --> 00:21:38,890
really fun and super powerful

322
00:21:38,890 --> 00:21:42,420
but if it for some reason is too
confusing or limiting are you feeling

323
00:21:42,420 --> 00:21:43,260
lazy

324
00:21:43,260 --> 00:21:47,320
CSS select is obviously a close second
choice

325
00:21:47,320 --> 00:21:50,790
cell I would say to use that cell

326
00:21:50,790 --> 00:21:54,140
I'd like to invite you to ask questions
again thanks for staying with me

327
00:21:54,140 --> 00:21:55,929
apologies for my technical

328
00:21:55,929 --> 00:22:00,570
difficulties I am KDM on Twitter if
you'd like to hit me up later if you

329
00:22:00,570 --> 00:22:02,490
want to explore the repository first

330
00:22:02,490 --> 00:22:06,070
I also idle on freenode as KJM

331
00:22:06,070 --> 00:22:13,070
and thank you so much for coming to my
talk

332
00:22:13,769 --> 00:22:20,649
and if you have questions there's a
microphone right there a high

333
00:22:20,649 --> 00:22:24,710
my guess is kinda a comment and then a
question

334
00:22:24,710 --> 00:22:27,990
okay by happily use lame quite a bit my
job

335
00:22:27,990 --> 00:22:32,480
OEQ on so I think that you live in
punching causes the way to determine

336
00:22:32,480 --> 00:22:35,610
what the form is a slim looks like is
now actually a fair representation

337
00:22:35,610 --> 00:22:38,980
%uh mainly because slam team is actually
a protocol

338
00:22:38,980 --> 00:22:43,750
that communicates with browser netscape
telling with not sick all the pipe on

339
00:22:43,750 --> 00:22:45,429
interface is doing is just calling

340
00:22:45,429 --> 00:22:48,850
on the remote interface that
communicates with it I'm so

341
00:22:48,850 --> 00:22:52,450
you pry wouldn't it few figure out why
the performances

342
00:22:52,450 --> 00:22:56,169
on you know lacking or you know they
perform it that way

343
00:22:56,169 --> 00:23:01,460
okay on and also the various calls that
were driver actually

344
00:23:01,460 --> 00:23:05,340
incorporates what drivers the underlying
infinite piece for a slim

345
00:23:05,340 --> 00:23:12,169
on sign a disconnect but on actually
depends on how the browser chooses to

346
00:23:12,169 --> 00:23:12,750
implement

347
00:23:12,750 --> 00:23:16,639
protocol okay I'm some use to see the
existing jobs for attention others

348
00:23:16,639 --> 00:23:17,820
utilize more

349
00:23:17,820 --> 00:23:21,970
built-in functionality these have do you
have advice on which driver is the

350
00:23:21,970 --> 00:23:22,700
fastest

351
00:23:22,700 --> 00:23:26,580
ya its a pansy ass is actually a
headless browser

352
00:23:26,580 --> 00:23:31,139
worse on and you can run into thousands
and processing as we do my job

353
00:23:31,139 --> 00:23:34,549
and it tends to be a lot faster than I'm
guessing

354
00:23:34,549 --> 00:23:38,279
me most people can't use Internet
Explorer Firefox mom in Yachats

355
00:23:38,279 --> 00:23:42,529
if found yet 10 times depending on work
at st. running

356
00:23:42,529 --> 00:23:46,519
there's also a headless chrome now as
well yes I am

357
00:23:46,519 --> 00:23:49,750
i'd have a spot a headless chrome
browser 0 their knees

358
00:23:49,750 --> 00:23:53,480
nice I will I was wondering just if you
need a comparison between the headless

359
00:23:53,480 --> 00:23:55,019
chrome and the Phantom JS

360
00:23:55,019 --> 00:23:59,429
haven't tried to help grow om and as
curious but Press reach us use for your

361
00:23:59,429 --> 00:24:00,230
slim test

362
00:24:00,230 --> 00:24:03,769
up for the slain to just use Firefox
area is fairly slow

363
00:24:03,769 --> 00:24:07,899
usually I use Chrome but I wanted to an
example that was easily portable for

364
00:24:07,899 --> 00:24:08,389
everyone

365
00:24:08,389 --> 00:24:13,019
that I thank you thank you a

366
00:24:13,019 --> 00:24:18,700
thanks for the talk um just curious what
was the most interesting and are useful

367
00:24:18,700 --> 00:24:22,809
land or cool I guess think you scraped
on

368
00:24:22,809 --> 00:24:27,190
in all my time scraping I yeah I'm up
probably

369
00:24:27,190 --> 00:24:31,190
at one point in time I was using a
service with my company

370
00:24:31,190 --> 00:24:34,760
we're utilizing a service to you help us
to some logging

371
00:24:34,760 --> 00:24:38,639
and I exposed a basically a heated API

372
00:24:38,639 --> 00:24:42,690
at some point I'm I just pinged the dev
team and said hey I found that I can go

373
00:24:42,690 --> 00:24:43,129
back

374
00:24:43,129 --> 00:24:47,379
like a year but if I wanted to go back
more than a year what can I use and

375
00:24:47,379 --> 00:24:50,889
they wrote me back saying our closing
that API and points

376
00:24:50,889 --> 00:24:54,360
apologies I didn't mean to be evil

377
00:24:54,360 --> 00:25:01,299
any other question

378
00:25:01,299 --> 00:25:05,100
all right thank you so much and I have a
happy

379
00:25:05,100 --> 00:25:05,450
icon

